(window.webpackJsonp=window.webpackJsonp||[]).push([[68],{468:function(a,t,e){"use strict";e.r(t);var r=e(3),s=Object(r.a)({},(function(){var a=this,t=a._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"面试题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#面试题"}},[a._v("#")]),a._v(" 面试题")]),a._v(" "),t("h2",{attrs:{id:"springaop动态代理默认是jdk还是cglib"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#springaop动态代理默认是jdk还是cglib"}},[a._v("#")]),a._v(" springAOP动态代理默认是jdk还是cglib?")]),a._v(" "),t("p",[a._v("spring中aop动态代理默认是jdk, cglib是第三方代理机制, 不过在springboot中好像就是cglib了")]),a._v(" "),t("h2",{attrs:{id:"事务的四大特性-acid"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#事务的四大特性-acid"}},[a._v("#")]),a._v(" 事务的四大特性 ACID")]),a._v(" "),t("p",[a._v("原子性, 一致性, 隔离性, 持久性")]),a._v(" "),t("p",[a._v("通过transaction注解进行事务时,通过参数isolation可以设置隔离级别, propagation可以设置传播级别")]),a._v(" "),t("p",[a._v("事务是使用代理对象控制的 如果同一个类下方法互相调用,A调用BC,那么不管BC怎么设置都和A相同的事务;, 因为绕过了代理对象, 如果注入自身再调用是可以的(但是自身循环依赖会出问题的) 如果是不同的类,A调用BC, B设置默认PROPAGATION_REQUIRED ,C设置PROPAGATION_REQUIRES_NEW ,那么B和A同一个事务, C自己一个事务")]),a._v(" "),t("h2",{attrs:{id:"本地事务失效"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#本地事务失效"}},[a._v("#")]),a._v(" 本地事务失效")]),a._v(" "),t("p",[a._v("同一个对象内事务方法互调默认失效, 原因: 绕过了代理对象, 事务使用代理对象来控制 解决: 使用代理对象来调用事务 1.引入aop-starter; spring-boot-starter-aop; 引入了aspectj 2.在类上注解@EnableAspectJAutoProxy(exposeProxy = true); 开启aspectj动态代理功能, 对外暴露对象 3.本类互相调用, AopContext.currentProxy();即可获取代理对象")]),a._v(" "),t("h2",{attrs:{id:"事务传播等级"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#事务传播等级"}},[a._v("#")]),a._v(" 事务传播等级")]),a._v(" "),t("p",[a._v("七种")]),a._v(" "),t("p",[a._v("PROPAGATION_REQUIRED 支持当前事务。如果没有事务则开启一个新的事务。 PROPAGATION_SUPPORTS 支持当前事务。如果没有事务，则非事务的执行。但是对于事务同步的事务管理器， PROPAGATION_MANDATORY 支持当前事务。如果没有一个活动的事务，则抛出异常。 PROPAGATION_REQUIRES_NEW 开启一个新的事务。如果一个事务已经存在，则将这个存在的事务挂起。 PROPAGATION_NOT_SUPPORTED 总是非事务地执行，并挂起任何存在的事务。 PROPAGATION_NEVER 总是非事务地执行，如果存在一个活动事务，则抛出异常 PROPAGATION_NESTED 如果一个活动的事务存在，则运行在一个嵌套的事务中.")]),a._v(" "),t("h2",{attrs:{id:"分布式事务"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#分布式事务"}},[a._v("#")]),a._v(" 分布式事务")]),a._v(" "),t("p",[a._v("本地事务: 微服务之间feign调用,会存在网络问题, 异常传递不靠谱, 比如B成功了但是因为网络问题未响应结果, A认为调用超时了就会回滚; 如果A同时调用B和C , B成功, C异常没有办法使B进行回滚")]),a._v(" "),t("h3",{attrs:{id:"_1-2pc模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-2pc模式"}},[a._v("#")]),a._v(" 1. 2PC模式")]),a._v(" "),t("p",[a._v("数据库支持2PC,是一个两阶段提交协议:")]),a._v(" "),t("p",[a._v("第一阶段:事务调节器要求每个涉及到事务的数据库预提交此操作, 并反映是否可以提交")]),a._v(" "),t("p",[a._v("第二阶段:事务提交器要求每个数据库提交数据")]),a._v(" "),t("p",[a._v("如果有一个数据库否决了此次提交, 那么所有数据库回滚此事务中操作")]),a._v(" "),t("h3",{attrs:{id:"_2-柔性事务-tcc事务补偿型方案"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-柔性事务-tcc事务补偿型方案"}},[a._v("#")]),a._v(" 2. 柔性事务-TCC事务补偿型方案")]),a._v(" "),t("p",[a._v("遵循BASE理论, 最终一致性. 允许一定时间内不同节点的数据不一致,但要求最终一致性")]),a._v(" "),t("h3",{attrs:{id:"_3-柔性事务-最大努力通知型方案"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-柔性事务-最大努力通知型方案"}},[a._v("#")]),a._v(" 3. 柔性事务-最大努力通知型方案")]),a._v(" "),t("p",[a._v("按规律进行通知, 不保证数据一定能通知成功, 但会提供可查询操作接口进行核对, 这种方案主要用于第三方系统通讯时, 比如: 调用微信或支付宝支付后的支付结果通知. 这种方案也是结合MQ进行实现, 例如通过MQ发送http请求, 设置最大通知次数, 达到次数后不再通知.")]),a._v(" "),t("p",[a._v("案例: 银行通知, 商户通知等(各大交易业务平台间的商户通知: 多次通知,查询校对,对账文件), 支付宝的支付成功异步回调")]),a._v(" "),t("h3",{attrs:{id:"_4-柔性事务-可靠消息-最终一致性方案-异步确保型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-柔性事务-可靠消息-最终一致性方案-异步确保型"}},[a._v("#")]),a._v(" 4. 柔性事务-可靠消息+最终一致性方案(异步确保型)")]),a._v(" "),t("p",[a._v("实现: 业务处理服务在业务事务提交之前, 向实时消息服务请求发送消息, 实时消息服务只记录消息数据, 而不是真正的发送. 业务处理服务在业务事务提交之后, 向实时消息服务确认发送. 只有在得到确认发送指令之后, 实时消息服务才会真正发送")]),a._v(" "),t("h3",{attrs:{id:"实现案例"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#实现案例"}},[a._v("#")]),a._v(" 实现案例:")]),a._v(" "),t("h3",{attrs:{id:"_1-使用seata用at-自动-模式控制分布式事务"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-使用seata用at-自动-模式控制分布式事务"}},[a._v("#")]),a._v(" 1. 使用Seata用AT(自动)模式控制分布式事务")]),a._v(" "),t("ol",[t("li",[a._v("每一个微服务先必须创建undo_log表")]),a._v(" "),t("li",[a._v("安装seata服务")]),a._v(" "),t("li",[a._v("整合步骤:\n"),t("ol",[t("li",[a._v("导入seata依赖 alibaba-seata")]),a._v(" "),t("li",[a._v("seata服务的配置文件 registry.conf 注册中心配置")]),a._v(" "),t("li",[a._v("所有想要用到分布式事务的微服务,使用seata代理数据源(尚硅谷P290)")]),a._v(" "),t("li",[a._v("每个微服务都导入seata的file.conf和registry.conf 需要改配置文件")]),a._v(" "),t("li",[a._v("使用时在分布式大事务的入口A方法上标注@GlobalTransactional全局事务注解")]),a._v(" "),t("li",[a._v("每一个远程小事务用本地事务@Transactional即可")])])]),a._v(" "),t("li",[a._v("缺点:不适合高并发场景")])]),a._v(" "),t("h2",{attrs:{id:"脏读、不可重复读、幻读"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#脏读、不可重复读、幻读"}},[a._v("#")]),a._v(" 脏读、不可重复读、幻读")]),a._v(" "),t("p",[a._v("脏读: 读取到了其他事务还未提交的数据")]),a._v(" "),t("p",[a._v("不可重复读: 在一个事务中 两次查询数据不一致, 可能是查询过程中其他事务更新了数据")]),a._v(" "),t("p",[a._v("幻读: 在一个事务内读取到了其他事务提交的数据")]),a._v(" "),t("h2",{attrs:{id:"数据隔离等级"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#数据隔离等级"}},[a._v("#")]),a._v(" 数据隔离等级")]),a._v(" "),t("p",[t("strong",[a._v("Serializable (串行化)：可避免脏读、不可重复读、幻读的发生")])]),a._v(" "),t("p",[a._v("该级别是最高级别的隔离级。它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简而言之，SERIALIZABLE是在每个读的数据行上加锁。在这个级别，可能导致大量的超时Timeout和锁竞争LockContention现象，实际应用中很少使用到这个级别，但如果用户的应用为了数据的稳定性，需要强制减少并发的话，也可以选择这种隔离级")]),a._v(" "),t("p",[t("strong",[a._v("Repeatable read (可重复读)：可避免脏读、不可重复读的发生")])]),a._v(" "),t("p",[a._v("MySQL数据库默认的隔离级别。该级别解决了READ UNCOMMITTED隔离级别导致的问题。它保证同一事务的多个实例在并发读取事务时，会“看到同样的”数据行。不过，这会导致另外一个棘手问题“幻读”。InnoDB和Falcon存储引擎通过多版本并发控制机制解决了幻读问题。")]),a._v(" "),t("p",[t("strong",[a._v("Read committed (读已提交)：可避免脏读的发生")])]),a._v(" "),t("p",[a._v("大多数数据库系统的默认隔离级别（但是不是MySQL的默认隔离级别），满足了隔离的早先简单定义：一个事务开始时，只能“看见”已经提交事务所做的改变，一个事务从开始到提交前，所做的任何数据改变都是不可见的，除非已经提交。这种隔离级别也支持所谓的“不可重复读”。这意味着用户运行同一个语句两次，看到的结果是不同的。")]),a._v(" "),t("p",[t("strong",[a._v("Read uncommitted (读未提交)：最低级别，任何情况都无法保证")])]),a._v(" "),t("p",[a._v("在这个隔离级别，所有事务都可以“看到”未提交事务的执行结果。在这种级别上，可能会产生很多问题，除非用户真的知道自己在做什么，并有很好的理由选择这样做。本隔离级别很少用于实际应用，因为它的性能也不必其他性能好多少，而别的级别还有其他更多的优点。读取未提交数据，也被称为“脏读”")]),a._v(" "),t("h2",{attrs:{id:"mysql存储引擎有几种"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#mysql存储引擎有几种"}},[a._v("#")]),a._v(" mysql存储引擎有几种?")]),a._v(" "),t("p",[a._v("InnoDB和MyISAM")]),a._v(" "),t("h2",{attrs:{id:"redis持久化方式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis持久化方式"}},[a._v("#")]),a._v(" redis持久化方式")]),a._v(" "),t("p",[a._v("RDB和AOF")]),a._v(" "),t("p",[t("strong",[a._v("两者的区别")])]),a._v(" "),t("p",[a._v("RDB持久化是定期将内存中的数据快照写入磁盘")]),a._v(" "),t("p",[a._v("AOF持久化是日志的形式记录服务器所处理的写删操作")]),a._v(" "),t("h2",{attrs:{id:"redis数据更新"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis数据更新"}},[a._v("#")]),a._v(" redis数据更新")]),a._v(" "),t("p",[a._v("当数据库数据需要更新时, 是先更新redis还是先更新数据库呢?")]),a._v(" "),t("p",[a._v("先更新数据库再更新缓存, 这样无论哪一步出现问题,最多用户拿到旧数据")]),a._v(" "),t("p",[a._v("从并发情况和数据一致性进行分析:")]),a._v(" "),t("p",[a._v("如果两步都没有出错, 那么先更新数据库不会有一致性问题, 而先更新缓存在并发情况下会出现一致性问题")]),a._v(" "),t("p",[a._v("如果两步中有其中一步出错, …")]),a._v(" "),t("p",[a._v("先更新数据库加过期时间比较好")]),a._v(" "),t("h2",{attrs:{id:"为什么使用iterator-它的用法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#为什么使用iterator-它的用法"}},[a._v("#")]),a._v(" 为什么使用Iterator, 它的用法")]),a._v(" "),t("p",[a._v("Iterator是用于遍历集合的标准方法, 他可以将访问逻辑从不同类型的集合中抽象出来, 从而避免暴露集合的内部结构, 而且Iterator是通过底层指针的挪动实现的遍历, 所以当集合类型改变时, 遍历代码不需要重写.")]),a._v(" "),t("p",[a._v("ListIterator可以双向迭代")]),a._v(" "),t("h2",{attrs:{id:"autowired注解底层的注入方式-还有哪些注解-如果bean同名怎么办"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#autowired注解底层的注入方式-还有哪些注解-如果bean同名怎么办"}},[a._v("#")]),a._v(" @autowired注解底层的注入方式, 还有哪些注解? 如果bean同名怎么办?")]),a._v(" "),t("p",[a._v("发现@autowired注解后, 根据当前bean类型找spring中是否有唯一该类型的bean, 如果有则注入, 如果存在多个则检查和当前bean名称相同的bean, 如果存在则注入不存在则抛异常")]),a._v(" "),t("p",[a._v("@Qualifier(value=“dog1”) 可以使用这个注解指定bean的name")]),a._v(" "),t("p",[a._v("@Primary 注解可以指定默认情况是,该类型注入的bean, 优先级比@Qualifier低")]),a._v(" "),t("h2",{attrs:{id:"springboot和ssm的对比"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#springboot和ssm的对比"}},[a._v("#")]),a._v(" springboot和ssm的对比")]),a._v(" "),t("p",[a._v("springboot是一个辅助型框架,为了提高效率")]),a._v(" "),t("p",[a._v("可以将服务打成jar包独立运行")]),a._v(" "),t("p",[a._v("简化配置文件")]),a._v(" "),t("h2",{attrs:{id:"springboot常用注解"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#springboot常用注解"}},[a._v("#")]),a._v(" springboot常用注解")]),a._v(" "),t("p",[a._v("@SpringBootApplication 核心注解,用在主类上 @RestController @Service @Mapper 标识控制层,业务层,数据层 @RequestMapping 处理请求路径映射的注解 @PostMapping @GetMapping @PathVariable 路径变量")]),a._v(" "),t("h2",{attrs:{id:"常用的设计模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#常用的设计模式"}},[a._v("#")]),a._v(" 常用的设计模式")]),a._v(" "),t("p",[a._v("单例模式, 工厂模式, 代理模式")]),a._v(" "),t("h2",{attrs:{id:"springcloud常用的注解"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#springcloud常用的注解"}},[a._v("#")]),a._v(" springCloud常用的注解")]),a._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v('@EnableDiscoveryClient   //开启注册,将该微服务注册到注册中心@MapperScan("com.atguigu.gulimall.product.dao")   //指定map的@SpringBootApplication   //springboot的核心注解\n')])])]),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v('//feign@EnableFeignClients   //当前微服务可以被远程调用@FeignClient("coupon")   //类上注解指定微服务的名称@RequestMapping("/coupon/coupon/member/list")   //方法上指定方法路径\n')])])]),t("h2",{attrs:{id:"如果面对并发问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如果面对并发问题"}},[a._v("#")]),a._v(" 如果面对并发问题")]),a._v(" "),t("p",[a._v("1.加锁 分为单机锁和分布式锁 如果服务在多台机器上那么使用redis实现分布锁")]),a._v(" "),t("p",[a._v("2.数据库乐观锁 在数据库表中添加版本号, 每次修改删除都要匹配版本号")]),a._v(" "),t("h2",{attrs:{id:"nginx负载均衡的方式-以及匹配-abc-和-abc的区别"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#nginx负载均衡的方式-以及匹配-abc-和-abc的区别"}},[a._v("#")]),a._v(" nginx负载均衡的方式, 以及匹配/abc/和/abc的区别")]),a._v(" "),t("p",[a._v("轮询, 权重, ip黏着")]),a._v(" "),t("p",[a._v("配置权重,在轮询基础上 weight = 权重值(占比)")]),a._v(" "),t("p",[a._v("匹配/abc和/abc/的区别:")]),a._v(" "),t("p",[a._v("location 匹配是模糊匹配, 如果最后有/ 那么只能匹配目录不能匹配文件")]),a._v(" "),t("p",[a._v("proxy_pass后面的, 如果https:// 后面的内容还有 / , 那么location就不会保留")]),a._v(" "),t("h2",{attrs:{id:"redis的内存穿透"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis的内存穿透"}},[a._v("#")]),a._v(" redis的内存穿透")]),a._v(" "),t("p",[a._v("redis缓存穿透是因为当查询一个一定不存在的数据时, 由于缓存中不命中便会查询数据库, 查不到数据就不写入缓存, 这样每次查这个不存在的数据都会去查数据库, 造成缓存穿透.")]),a._v(" "),t("p",[a._v("解决方法:")]),a._v(" "),t("p",[a._v("1.布隆过滤")]),a._v(" "),t("p",[a._v("对所有可能查询的参数以hash形式存储, 在控制层进行校验, 不符合则丢弃. 常见的还有使用布隆过滤器, 将所有可能存在的数据hash到一个bitmap中, 一个一定不存在的数据会被bitmap拦截掉, 从而避免对底层存储的查询")]),a._v(" "),t("p",[a._v("2.缓存空对象")]),a._v(" "),t("p",[a._v("当查询为空时, 将这个空对象进行缓存 , 过期时间给短一些")]),a._v(" "),t("h2",{attrs:{id:"缓存击穿"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#缓存击穿"}},[a._v("#")]),a._v(" 缓存击穿")]),a._v(" "),t("p",[a._v("key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。")]),a._v(" "),t("p",[a._v("解决方法:")]),a._v(" "),t("p",[a._v("1.使用互斥锁(mutex key)")]),a._v(" "),t("p",[a._v("当判断失效时(value为null), 不立即去读数据库, 使用redis的SETNX存储一个标识key, 如果存储成功了, 则读数据库, 写入缓存, 删除这个标识key ; 如果存储标识key失败了, 意味着有其他线程已经在做读库操作了, 让当前线程sleep一段时间后重试")]),a._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("ublic String get(key) {      String value = redis.get(key);      if (value == null) { //代表缓存值过期          //设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db      if (redis.setnx(key_mutex, 1, 3 * 60) == 1) {  //代表设置成功               value = db.get(key);                      redis.set(key, value, expire_secs);                      redis.del(key_mutex);              } else {  //这个时候代表同时候的其他线程已经load db并回设到缓存了，这时候重试获取缓存值即可                      sleep(50);                      get(key);  //重试              }          } else {              return value;          } }\n")])])]),t("h2",{attrs:{id:"缓存雪崩"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#缓存雪崩"}},[a._v("#")]),a._v(" 缓存雪崩")]),a._v(" "),t("p",[a._v("与击穿的区别在于,是大量的key失效, 一旦缓存大量丢失缓存数据,就造成海量请求瞬间进入数据库,导致数据库崩溃–雪崩;redis出现雪崩,只需要恢复数据(持久化),memoryCache出现雪崩,只能停止服务手动将数据恢复到内存中,继续提供服务")]),a._v(" "),t("p",[a._v("解决方法:")]),a._v(" "),t("p",[a._v("1.线程加锁, 但是对出现一线程执行多线程等待 , 影响并发")]),a._v(" "),t("p",[a._v("2.在原有失效时间上加个随机值, 让每个key的过期时间尽量错开, 避免集体失效")]),a._v(" "),t("p",[a._v("3.做二级缓存, 或者双缓存机制 做两份缓存A和B, B不设失效时间, 这样当A失效后拿B的数据去返回, 同时异步启动一个更新线程, 将更新的数据同步到A和B")]),a._v(" "),t("h2",{attrs:{id:"springboot的启动机制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#springboot的启动机制"}},[a._v("#")]),a._v(" springboot的启动机制")]),a._v(" "),t("h2",{attrs:{id:"java常用的数据结构有哪些-哪些是线程安全的-是怎么保证线程安全的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#java常用的数据结构有哪些-哪些是线程安全的-是怎么保证线程安全的"}},[a._v("#")]),a._v(" java常用的数据结构有哪些? 哪些是线程安全的? 是怎么保证线程安全的?")]),a._v(" "),t("p",[a._v("java常用的数据结构,主要分为Collection和map两个接口. 而最终使用的数据结构是继承自这些接口的数据结构类.")]),a._v(" "),t("h2",{attrs:{id:"hashmap可以使用基本数据类型做key吗"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hashmap可以使用基本数据类型做key吗"}},[a._v("#")]),a._v(" hashmap可以使用基本数据类型做key吗?")]),a._v(" "),t("p",[a._v("不能, 因为基本数据类型不能调用 hashcode() 和 equals() 方法, 可以使用基本类型的包装类")]),a._v(" "),t("h2",{attrs:{id:"linkedhashmap原理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#linkedhashmap原理"}},[a._v("#")]),a._v(" LinkedHashMap原理")]),a._v(" "),t("p",[a._v("LinkedHashMap可以存储元素的先后顺序, 原理是基于hashmap + 双向链表")]),a._v(" "),t("p",[a._v("继承了hashmap,")]),a._v(" "),t("h2",{attrs:{id:"线程池"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#线程池"}},[a._v("#")]),a._v(" 线程池")]),a._v(" "),t("h3",{attrs:{id:"线程池的优势"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#线程池的优势"}},[a._v("#")]),a._v(" 线程池的优势")]),a._v(" "),t("p",[a._v("1.降低系统资源消耗, 通过重用已存在的线程, 降低线程创建和销毁造成的消耗; 2.提高系统的响应速度, 当有任务到达时, 通过复用已存在的线程, 无需等待新线程的创建便能立即执行; 3.方便线程并发数的管控, 因为线程若是无限制的创建, 可能会导致内存占用过多而用尽内存, 并且会造成cpu过度切换 4.提供更强大的功能, 延时定时线程池.")]),a._v(" "),t("h3",{attrs:{id:"线程池的主要参数"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#线程池的主要参数"}},[a._v("#")]),a._v(" 线程池的主要参数")]),a._v(" "),t("p",[a._v("使用 ThreadPoolExecutor")]),a._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v(" public ThreadPoolExecutor(int corePoolSize,                           int maximumPoolSize,                           long keepAliveTime,                           TimeUnit unit,                           BlockingQueue<Runnable> workQueue,                           ThreadFactory threadFactory,                           RejectedExecutionHandler handler)\n")])])]),t("p",[a._v("corePoolSize (核心线程数量)")]),a._v(" "),t("p",[a._v("maximumPoolSize (最大线程数量)")]),a._v(" "),t("p",[a._v("keepAliveTime (线程存活时间): 非核心线程的存活时间")]),a._v(" "),t("p",[a._v("workQueue (任务队列): 用于传输和保存等待执行任务的阻塞队列")]),a._v(" "),t("p",[a._v("ThreadFactory (线程工厂)")]),a._v(" "),t("p",[a._v("Handler (拒绝策略): 当线程池和队列都满了, 在加入线程时会执行此策略")]),a._v(" "),t("p",[a._v("img")]),a._v(" "),t("h3",{attrs:{id:"拒绝策略"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#拒绝策略"}},[a._v("#")]),a._v(" 拒绝策略:")]),a._v(" "),t("p",[a._v("1.AbortPolicy: 不执行新任务, 直接抛出异常, 提示线程池已满 2.DisCardPolicy: 不执行新任务, 也不抛出异常 3.DisCardOldSetPolicy: 将消息队列中的第一个任务替换成当前新进来的任务执行 4.CallerRunsPolicy: 直接调用execute来执行当前任务")]),a._v(" "),t("h3",{attrs:{id:"常见的线程池"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#常见的线程池"}},[a._v("#")]),a._v(" 常见的线程池:")]),a._v(" "),t("p",[a._v("1.CachedThreadPool:可缓存的线程池，该线程池中没有核心线程，非核心线程的数量为Integer.max_value，就是无限大，当有需要时创建线程来执行任务，没有需要时回收线程，适用于耗时少，任务量大的情况。 2.SecudleThreadPool:周期性执行任务的线程池，按照某种特定的计划执行线程中的任务，有核心线程，但也有非核心线程，非核心线程的大小也为无限大。适用于执行周期性的任务。 3.SingleThreadPool:只有一条线程来执行任务，适用于有顺序的任务的应用场景。 4.FixedThreadPool:定长的线程池，有核心线程，核心线程的即为最大的线程数量，没有非核心线程")]),a._v(" "),t("h2",{attrs:{id:"数据连接池"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#数据连接池"}},[a._v("#")]),a._v(" 数据连接池")]),a._v(" "),t("p",[a._v("常见的数据库连接池主要有c3p0，dbcp，druid")]),a._v(" "),t("h2",{attrs:{id:"rebbitmq的优缺点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rebbitmq的优缺点"}},[a._v("#")]),a._v(" rebbitmq的优缺点")])])}),[],!1,null,null,null);t.default=s.exports}}]);