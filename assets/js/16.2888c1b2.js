(window.webpackJsonp=window.webpackJsonp||[]).push([[16],{330:function(a,t,s){"use strict";s.r(t);var e=s(3),r=Object(e.a)({},(function(){var a=this,t=a._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"hashmap"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hashmap"}},[a._v("#")]),a._v(" HashMap")]),a._v(" "),t("p",[a._v("HashMap 最早出现在 JDK 1.2中，底层基于散列算法实现。HashMap 允许 null 键和 null 值，在计算哈键的哈希值时，null 键哈希值为 0。HashMap 并不保证键值对的顺序，这意味着在进行某些操作后，键值对的顺序可能会发生变化。另外，需要注意的是，HashMap 是非线程安全类，在多线程环境下可能会存在问题。")]),a._v(" "),t("p",[a._v("初始化map的大小是16")]),a._v(" "),t("h1",{attrs:{id:"简单原理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#简单原理"}},[a._v("#")]),a._v(" 简单原理")]),a._v(" "),t("p",[a._v("如何理解hashMap的原理, 可以简化理解为数组+链表")]),a._v(" "),t("p",[a._v("将每个key的hash值与数组的长度取模运算得到一个数组的下标, 然后将key放入, 如果多个key在同一下标的情况, 那么它们在这个位置以链表的形式存储")]),a._v(" "),t("p",[a._v("以上就是最简化的思路")]),a._v(" "),t("h1",{attrs:{id:"扰动函数"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#扰动函数"}},[a._v("#")]),a._v(" 扰动函数")]),a._v(" "),t("p",[a._v("简单的取模运算分布还不够随机, 所以在取到哈希值后还进行了扰动运算 (h = key.hashCode()) ^ (h >>> 16) . 将哈希值右移16位, 也就是自己长度的一半, 之后与哈希值做异或运算, 这样混合了原哈希值中的高位和低位, 增大了随机性.")]),a._v(" "),t("p",[a._v("使用扰动函数就是为了增加随机性, 让数据元素更加均衡的散列, 减少碰撞")]),a._v(" "),t("h1",{attrs:{id:"初始化容量和负载因子"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#初始化容量和负载因子"}},[a._v("#")]),a._v(" 初始化容量和负载因子")]),a._v(" "),t("h2",{attrs:{id:"初始化容量"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#初始化容量"}},[a._v("#")]),a._v(" 初始化容量")]),a._v(" "),t("p",[a._v("默认容量为16")]),a._v(" "),t("p",[a._v("初始容量为2的倍数时, 才会出现01111这样的值")]),a._v(" "),t("p",[a._v("如果初始化HashMap时定义的长度不是2的倍数, 那么会寻找比初始值大的最小的那个2进制数值, 比如17会找到32")]),a._v(" "),t("h2",{attrs:{id:"负载因子"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#负载因子"}},[a._v("#")]),a._v(" 负载因子")]),a._v(" "),t("p",[a._v("默认负载因子是0.75f")]),a._v(" "),t("p",[a._v("在HashMap中, 负载因子决定了数据量多少以后进行扩容")]),a._v(" "),t("p",[a._v("所以默认值0.75f , 是在数组长度的3/4的下标被使用时, 会进行扩容")]),a._v(" "),t("h1",{attrs:{id:"扩容元素拆分"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#扩容元素拆分"}},[a._v("#")]),a._v(" 扩容元素拆分")]),a._v(" "),t("p",[a._v("在扩容时需要将元素重新拆分到新的数组中. 拆分过程中, jdk1.7还会重新计算哈希值, 1.8之后不在重新计算")]),a._v(" "),t("h2",{attrs:{id:"数据迁移"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#数据迁移"}},[a._v("#")]),a._v(" 数据迁移")]),a._v(" "),t("p",[a._v("通过测试发现 原扰动哈希值与扩容新增出来的长度16, 进行&运算, 如果值等于0, 则不需要变动位置, 不为0需要在原位置加上新增长度")]),a._v(" "),t("p",[a._v("这样就不用每个元素重新计算扰动hash")]),a._v(" "),t("h1",{attrs:{id:"插入"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#插入"}},[a._v("#")]),a._v(" 插入")]),a._v(" "),t("p",[a._v("HashMap插入数据流程图")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://bugstack.cn/assets/images/2020/interview/interview-5-01.png",alt:"https://bugstack.cn/assets/images/2020/interview/interview-5-01.png"}})]),a._v(" "),t("ol",[t("li",[t("p",[a._v("进行哈希值扰动, 得到新哈希值 。"),t("code",[a._v("tab[i = (n - 1) & hash])")])])]),a._v(" "),t("li",[t("p",[a._v("判断tab是否为空或者长度为0 , 如果是进行扩容操作")]),a._v(" "),t("div",{staticClass:"language-java extra-class"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("// 初始化桶数组 table，table 被延迟到插入新数据时再进行初始化")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("if")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("tab "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" table"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("null")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("||")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("n "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" tab"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("length"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n    n "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("tab "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("resize")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("length"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n")])])])]),a._v(" "),t("li",[t("p",[a._v("根据哈希值计算下标, 如果对应下标没有存放数据, 则直接插入;\n如果存在值并且key也存在则进行值覆盖")])]),a._v(" "),t("li",[t("p",[a._v("如果key不存在, 判断当前下标中是否是树节点, 是则向树节点插入数据, 否则向链表插入数据")])]),a._v(" "),t("li",[t("p",[a._v("向链表插入数据时, 判断链表长度大于等于8, 则需要把链表转换为红黑树。"),t("code",[a._v("treeifyBin(tab, hash);")])])]),a._v(" "),t("li",[t("p",[a._v("最后所有元素处理完之后, 判断是否超过阈值, 超过则扩容")])]),a._v(" "),t("li",[t("p",[t("code",[a._v("treeifyBin")]),a._v(",是一个链表转树的方法，但不是所有的链表长度为8后都会转成树，还需要判断存放key值的数组桶长度是否小于64 "),t("code",[a._v("MIN_TREEIFY_CAPACITY")]),a._v("。如果小于则需要扩容，扩容后链表上的数据会被拆分散列的相应的桶节点上，也就把链表长度缩短了。")])])]),a._v(" "),t("h2",{attrs:{id:"扩容机制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#扩容机制"}},[a._v("#")]),a._v(" 扩容机制")]),a._v(" "),t("p",[a._v("HashMap是基于数组+链表和红黑树实现的, 但用于存放key值的数组桶的长度时固定的, 由初始化决定.")]),a._v(" "),t("ol",[t("li",[a._v("扩容时计算出新的newCap、newThr，这是两个单词的缩写，一个是Capacity ，另一个是阀Threshold")]),a._v(" "),t("li",[a._v("newCap用于创新的数组桶 "),t("code",[a._v("new Node[newCap];")])]),a._v(" "),t("li",[a._v("随着扩容后，原来那些因为哈希碰撞，存放成链表和红黑树的元素，都需要进行拆分存放到新的位置中。")])]),a._v(" "),t("h2",{attrs:{id:"链表树化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#链表树化"}},[a._v("#")]),a._v(" 链表树化")]),a._v(" "),t("p",[a._v("HashMap这种散列表的数据结构，最大的性能在于可以O(1)时间复杂度定位到元素，但因为哈希碰撞不得已在一个下标里存放多组数据，那么jdk1.8之前的设计只是采用链表的方式进行存放，如果需要从链表中定位到数据时间复杂度就是O(n)，链表越长性能越差。因为在jdk1.8中把过长的链表也就是8个，优化为自平衡的红黑树结构，以此让定位元素的时间复杂度优化近似于O(logn)，这样来提升元素查找的效率。但也不是完全抛弃链表，因为在元素相对不多的情况下，链表的插入速度更快，所以综合考虑下设定阈值为8才进行红黑树转换操作。")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://bugstack.cn/assets/images/2020/interview/interview-5-02.png",alt:"https://bugstack.cn/assets/images/2020/interview/interview-5-02.png"}})]),a._v(" "),t("ol",[t("li",[a._v("链表树化的条件有两点；链表长度大于等于8、桶容量大于64，否则只是扩容，不会树化。")]),a._v(" "),t("li",[a._v("链表树化的过程中是先由链表转换为树节点，此时的树可能不是一颗平衡树。同时在树转换过程中会记录链表的顺序，"),t("code",[a._v("tl.next = p")]),a._v("，这主要方便后续树转链表和拆分更方便。")]),a._v(" "),t("li",[a._v("链表转换成树完成后，在进行红黑树的转换。先简单介绍下，红黑树的转换需要染色和旋转，以及比对大小。在比较元素的大小中，有一个比较有意思的方法，"),t("code",[a._v("tieBreakOrder")]),a._v("加时赛，这主要是因为HashMap没有像TreeMap那样本身就有Comparator的实现。")])]),a._v(" "),t("h1",{attrs:{id:"查找"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#查找"}},[a._v("#")]),a._v(" 查找")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://bugstack.cn/assets/images/2020/interview/interview-5-03.png",alt:"https://bugstack.cn/assets/images/2020/interview/interview-5-03.png"}})]),a._v(" "),t("h1",{attrs:{id:"删除"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#删除"}},[a._v("#")]),a._v(" 删除")]),a._v(" "),t("h1",{attrs:{id:"遍历"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#遍历"}},[a._v("#")]),a._v(" 遍历")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://bugstack.cn/assets/images/2020/interview/interview-5-05.png",alt:"https://bugstack.cn/assets/images/2020/interview/interview-5-05.png"}})]),a._v(" "),t("p",[a._v("第一顺序是按照数组下标进行遍历, 数组桶中的元素按照链表首尾顺序遍历,")])])}),[],!1,null,null,null);t.default=r.exports}}]);